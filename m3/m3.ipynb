{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit default\n",
    "__Note on how to use this notebook:__ <br>\n",
    "1) Save the notebook to disk. <br>\n",
    "2) Save the [data set](https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls) to the same folder that this notebook was saved in. \n",
    "\n",
    "[Data description](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#) <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following runs the data preperation that is used for all models.\n",
    "\n",
    "We scale all features by Sci-Kit learn's standard scaler. The standard scalars subtracts the mean, so that the means of the standardized variables equal zero. Furthermore the standard scaler divides the feautres by their respective variances, so that the variances of the standardized features equals one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty elements in data:  False\n",
      "Observations:  28497\n",
      "Percentage defaults:  21.31452433589501\n"
     ]
    }
   ],
   "source": [
    "# Trying to set the seed\n",
    "np.random.seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "# Reading file into data frame\n",
    "cwd = os.getcwd()\n",
    "filename = cwd + '/default of credit card clients.xls'\n",
    "nanDict = {}\n",
    "df = pd.read_excel(filename, header=1, skiprows=0, index_col=0, na_values=nanDict)\n",
    "\n",
    "df.rename(index=str, columns={\"default payment next month\": \"defaultPaymentNextMonth\"}, inplace=True)\n",
    "\n",
    "# Features and targets \n",
    "X = df.loc[:, df.columns != 'defaultPaymentNextMonth'].values\n",
    "y = df.loc[:, df.columns == 'defaultPaymentNextMonth'].values\n",
    "\n",
    "# Categorical variables to one-hot's\n",
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:] \n",
    "\n",
    "# Train-test split\n",
    "trainingShare = 0.5 \n",
    "seed  = 1\n",
    "XTrain, XTest, yTrain, yTest=train_test_split(X, y, train_size=trainingShare, \\\n",
    "                                              test_size = 1-trainingShare,\n",
    "                                             random_state=seed)\n",
    "\n",
    "# Input Scaling\n",
    "sc = StandardScaler()\n",
    "XTrain = sc.fit_transform(XTrain)\n",
    "XTest = sc.transform(XTest)\n",
    "\n",
    "# One-hot's of the target vector\n",
    "Y_train_onehot, Y_test_onehot = to_categorical(yTrain), to_categorical(yTest)\n",
    "\n",
    "# Remove instances with zeros only for past bill statements or paid amounts\n",
    "'''\n",
    "df = df.drop(df[(df.BILL_AMT1 == 0) &\n",
    "                (df.BILL_AMT2 == 0) &\n",
    "                (df.BILL_AMT3 == 0) &\n",
    "                (df.BILL_AMT4 == 0) &\n",
    "                (df.BILL_AMT5 == 0) &\n",
    "                (df.BILL_AMT6 == 0) &\n",
    "                (df.PAY_AMT1 == 0) &\n",
    "                (df.PAY_AMT2 == 0) &\n",
    "                (df.PAY_AMT3 == 0) &\n",
    "                (df.PAY_AMT4 == 0) &\n",
    "                (df.PAY_AMT5 == 0) &\n",
    "                (df.PAY_AMT6 == 0)].index)\n",
    "'''\n",
    "df = df.drop(df[(df.BILL_AMT1 == 0) &\n",
    "                (df.BILL_AMT2 == 0) &\n",
    "                (df.BILL_AMT3 == 0) &\n",
    "                (df.BILL_AMT4 == 0) &\n",
    "                (df.BILL_AMT5 == 0) &\n",
    "                (df.BILL_AMT6 == 0)].index)\n",
    "\n",
    "df = df.drop(df[(df.PAY_AMT1 == 0) &\n",
    "                (df.PAY_AMT2 == 0) &\n",
    "                (df.PAY_AMT3 == 0) &\n",
    "                (df.PAY_AMT4 == 0) &\n",
    "                (df.PAY_AMT5 == 0) &\n",
    "                (df.PAY_AMT6 == 0)].index)\n",
    "\n",
    "# Descriptive information\n",
    "print('Number of empty elements in data: ', df.isnull().values.any())\n",
    "print('Observations: ', df.shape[0])\n",
    "print('Percentage defaults: ', df['defaultPaymentNextMonth'].astype(bool).sum(axis=0)/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not the same number of observations as in Yeh and Lien (2009). Yeh and Lien (2009) have 25 000 observations. However, we have the same number of observations as in Pyzhov and Pyzhov (2017), which is said to use the same dataset as Yeh and Lien (2009). \n",
    "\n",
    "The percentage of individuals with default is the same as in the Yeh and Lien (2009).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "We apply Sci-Kit learn's logistic regression method for performing classification of default and non-defaulting customers. It is possible to use regularization for the logistic regression. Regularization has the potential to reduce overfitting. We will apply Sci-Kit learn's Grid search function for identifying the optimal regularization value. The optimal regularization parameter is determined by the accuracy score on test sets applying K-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': array([1.e+05, 1.e+04, 1.e+03, 1.e+02, 1.e+01, 1.e+00, 1.e-01, 1.e-02,\n",
       "       1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07])}],\n",
       "       pre_dispatch='2*n_jobs', refit='roc_auc', return_train_score='warn',\n",
       "       scoring=['accuracy', 'roc_auc'], verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lmbdas=np.logspace(-5,7,13)\n",
    "parameters = [{'C': 1./lmbdas}]\n",
    "scoring = ['accuracy', 'roc_auc']\n",
    "logReg = LogisticRegression()\n",
    "gridSearch = GridSearchCV(logReg, parameters, cv=5, scoring=scoring, refit='roc_auc') \n",
    "# \"refit\" gives the metric used deciding best model. \n",
    "# See more http://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html\n",
    "gridSearch.fit(XTrain, yTrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearchSummary(method, scoring):\n",
    "    method = eval(method)\n",
    "    if scoring == 'accuracy':\n",
    "        mean = 'mean_test_score'\n",
    "        sd = 'std_test_score'\n",
    "    elif scoring == 'auc':\n",
    "        mean = 'mean_test_roc_auc'\n",
    "        sd = 'std_test_roc_auc'\n",
    "    print(\"Best: %f using %s\" % (method.best_score_, method.best_params_))\n",
    "    means = method.cv_results_[mean]\n",
    "    stds = method.cv_results_[sd]\n",
    "    params = method.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.723594 using {'C': 0.1}\n",
      "0.723494 (0.008033) with: {'C': 99999.99999999999}\n",
      "0.723494 (0.008033) with: {'C': 10000.0}\n",
      "0.723494 (0.008033) with: {'C': 1000.0}\n",
      "0.723495 (0.008033) with: {'C': 100.0}\n",
      "0.723496 (0.008036) with: {'C': 10.0}\n",
      "0.723518 (0.008048) with: {'C': 1.0}\n",
      "0.723594 (0.008032) with: {'C': 0.1}\n",
      "0.723440 (0.007838) with: {'C': 0.01}\n",
      "0.717568 (0.007688) with: {'C': 0.001}\n",
      "0.705035 (0.007697) with: {'C': 0.0001}\n",
      "0.699007 (0.007833) with: {'C': 1e-05}\n",
      "0.698128 (0.007831) with: {'C': 1e-06}\n",
      "0.698044 (0.007811) with: {'C': 1e-07}\n"
     ]
    }
   ],
   "source": [
    "gridSearchSummary('gridSearch', 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in terms of accuracy it does not matter much what the regularization parameter value is. The optimal parameter, among the chosen parameter values, is one, but the difference in test score between the eight first regularization parameter values is practically non-existent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function for printing accuracy results, confusion matrices and storing of these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createConfusionMatrix(method):\n",
    "    confusionArray = np.zeros(6, dtype=object)\n",
    "    method = eval(method)\n",
    "    \n",
    "    print('\\n###################  Training  ###############')\n",
    "    yPredTrain = method.predict(XTrain)\n",
    "    yPredTrain = (yPredTrain > 0.5)\n",
    "    cm = confusion_matrix(\n",
    "        yTrain, yPredTrain) \n",
    "    cm = np.around(cm/cm.sum(axis=1)[:,None], 2)\n",
    "    confusionArray[0] = cm\n",
    "    print('\\nTraining Confusion matrix: \\n', cm)\n",
    "    accScore = accuracy_score(yTrain, yPredTrain)\n",
    "    confusionArray[1] = accScore\n",
    "    print('\\nTraining Accuracy score: \\n', accScore)\n",
    "    AUC = roc_auc_score(yTrain, yPredTrain)\n",
    "    confusionArray[2] = AUC\n",
    "    print('\\nTrain AUC: \\n', AUC)\n",
    "    \n",
    "    print('\\n###################  Testing  ###############')\n",
    "    yPred = method.predict(XTest)\n",
    "    yPred = (yPred > 0.5)\n",
    "    cm = confusion_matrix(\n",
    "        yTest, yPred) \n",
    "    cm = np.around(cm/cm.sum(axis=1)[:,None], 2)\n",
    "    confusionArray[3] = cm\n",
    "    print('\\nTest Confusion matrix: \\n', cm)\n",
    "    accScore = accuracy_score(yTest, yPred)\n",
    "    confusionArray[4] = accScore\n",
    "    print('\\nTest Accuracy score: \\n', accScore)\n",
    "    AUC = roc_auc_score(yTest, yPred)\n",
    "    confusionArray[5] = AUC\n",
    "    print('\\nTestAUC: \\n', AUC)    \n",
    "    \n",
    "    return confusionArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n",
      "\n",
      "Training Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.75 0.25]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8157333333333333\n",
      "\n",
      "Train AUC: \n",
      " 0.6121174689352334\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.77 0.23]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8064\n",
      "\n",
      "TestAUC: \n",
      " 0.6028099335864404\n"
     ]
    }
   ],
   "source": [
    "confusionArrayLogreg = createConfusionMatrix('gridSearch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accurcies and AUC's on the testing set is higher the cooresponding best mean numbers on the validation sets from the K-fold cross validation. We see that only about $1/4$ of the defaults get correctly predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras NN\n",
    "We will now perform classification by deep neural networks. Keras is used. \n",
    "\n",
    "\n",
    "### Grid search\n",
    "We will apply Sci-Kit learn's grid search function in order to determine the optimal combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "def createModel(neurons =50, hiddenLayers = 2):\n",
    "    model = tf.keras.Sequential()\n",
    "    neuronsPerLayer = neurons // (hiddenLayers + 1)\n",
    "    model.add(tf.keras.layers.Dense(neuronsPerLayer, activation='relu', input_dim=XTrain.shape[1]))\n",
    "    for i in range(hiddenLayers):\n",
    "        model.add(tf.keras.layers.Dense(neuronsPerLayer, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(Y_train_onehot.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=createModel, verbose=0)\n",
    "\n",
    "neurons = [20, 50, 100, 200, 300, 400]# 500]\n",
    "hiddenLayers = [1, 2, 3, 5]\n",
    "batch_size = [5, 10, 32, 64]##, 40, 60, 80, 100]\n",
    "parameterGrid = [{'neurons': neurons, 'hiddenLayers': hiddenLayers, 'batch_size': batch_size}]\n",
    "folds = 3\n",
    "#scoring = ['accuracy', 'roc_auc']\n",
    "scoring = 'roc_auc'\n",
    "#grid = GridSearchCV(estimator=model, cv=folds, param_grid=parameterGrid, n_jobs=-1)\n",
    "#grid = GridSearchCV(estimator=model, cv=folds, param_grid=parameterGrid, n_jobs=-1, scoring=scoring, refit='roc_auc')\n",
    "grid = GridSearchCV(estimator=model, cv=folds, param_grid=parameterGrid, n_jobs=-1, scoring=scoring)\n",
    "\n",
    "epochs = 10\n",
    "grid_result = grid.fit(XTrain, Y_train_onehot, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.768249 using {'batch_size': 10, 'hiddenLayers': 2, 'neurons': 400}\n",
      "0.753683 (0.007299) with: {'batch_size': 5, 'hiddenLayers': 1, 'neurons': 20}\n",
      "0.762769 (0.006219) with: {'batch_size': 5, 'hiddenLayers': 1, 'neurons': 50}\n",
      "0.761585 (0.005592) with: {'batch_size': 5, 'hiddenLayers': 1, 'neurons': 100}\n",
      "0.764084 (0.003973) with: {'batch_size': 5, 'hiddenLayers': 1, 'neurons': 200}\n",
      "0.763744 (0.001852) with: {'batch_size': 5, 'hiddenLayers': 1, 'neurons': 300}\n",
      "0.762629 (0.005723) with: {'batch_size': 5, 'hiddenLayers': 1, 'neurons': 400}\n",
      "0.746633 (0.012947) with: {'batch_size': 5, 'hiddenLayers': 2, 'neurons': 20}\n",
      "0.763072 (0.004332) with: {'batch_size': 5, 'hiddenLayers': 2, 'neurons': 50}\n",
      "0.763237 (0.006100) with: {'batch_size': 5, 'hiddenLayers': 2, 'neurons': 100}\n",
      "0.763632 (0.007516) with: {'batch_size': 5, 'hiddenLayers': 2, 'neurons': 200}\n",
      "0.766475 (0.004893) with: {'batch_size': 5, 'hiddenLayers': 2, 'neurons': 300}\n",
      "0.766477 (0.006680) with: {'batch_size': 5, 'hiddenLayers': 2, 'neurons': 400}\n",
      "0.749985 (0.005090) with: {'batch_size': 5, 'hiddenLayers': 3, 'neurons': 20}\n",
      "0.756849 (0.004718) with: {'batch_size': 5, 'hiddenLayers': 3, 'neurons': 50}\n",
      "0.764139 (0.003763) with: {'batch_size': 5, 'hiddenLayers': 3, 'neurons': 100}\n",
      "0.767969 (0.007006) with: {'batch_size': 5, 'hiddenLayers': 3, 'neurons': 200}\n",
      "0.762722 (0.005932) with: {'batch_size': 5, 'hiddenLayers': 3, 'neurons': 300}\n",
      "0.765351 (0.004343) with: {'batch_size': 5, 'hiddenLayers': 3, 'neurons': 400}\n",
      "0.567066 (0.094846) with: {'batch_size': 5, 'hiddenLayers': 5, 'neurons': 20}\n",
      "0.762246 (0.008809) with: {'batch_size': 5, 'hiddenLayers': 5, 'neurons': 50}\n",
      "0.756843 (0.009519) with: {'batch_size': 5, 'hiddenLayers': 5, 'neurons': 100}\n",
      "0.765621 (0.004872) with: {'batch_size': 5, 'hiddenLayers': 5, 'neurons': 200}\n",
      "0.760848 (0.005580) with: {'batch_size': 5, 'hiddenLayers': 5, 'neurons': 300}\n",
      "0.761694 (0.005360) with: {'batch_size': 5, 'hiddenLayers': 5, 'neurons': 400}\n",
      "0.746366 (0.000669) with: {'batch_size': 10, 'hiddenLayers': 1, 'neurons': 20}\n",
      "0.757481 (0.006267) with: {'batch_size': 10, 'hiddenLayers': 1, 'neurons': 50}\n",
      "0.758694 (0.003795) with: {'batch_size': 10, 'hiddenLayers': 1, 'neurons': 100}\n",
      "0.761814 (0.006859) with: {'batch_size': 10, 'hiddenLayers': 1, 'neurons': 200}\n",
      "0.762329 (0.004851) with: {'batch_size': 10, 'hiddenLayers': 1, 'neurons': 300}\n",
      "0.763477 (0.003165) with: {'batch_size': 10, 'hiddenLayers': 1, 'neurons': 400}\n",
      "0.742950 (0.006163) with: {'batch_size': 10, 'hiddenLayers': 2, 'neurons': 20}\n",
      "0.756090 (0.006297) with: {'batch_size': 10, 'hiddenLayers': 2, 'neurons': 50}\n",
      "0.758576 (0.010223) with: {'batch_size': 10, 'hiddenLayers': 2, 'neurons': 100}\n",
      "0.766465 (0.001967) with: {'batch_size': 10, 'hiddenLayers': 2, 'neurons': 200}\n",
      "0.763937 (0.004989) with: {'batch_size': 10, 'hiddenLayers': 2, 'neurons': 300}\n",
      "0.768249 (0.005456) with: {'batch_size': 10, 'hiddenLayers': 2, 'neurons': 400}\n",
      "0.737381 (0.004443) with: {'batch_size': 10, 'hiddenLayers': 3, 'neurons': 20}\n",
      "0.751790 (0.016250) with: {'batch_size': 10, 'hiddenLayers': 3, 'neurons': 50}\n",
      "0.754395 (0.005013) with: {'batch_size': 10, 'hiddenLayers': 3, 'neurons': 100}\n",
      "0.764261 (0.002840) with: {'batch_size': 10, 'hiddenLayers': 3, 'neurons': 200}\n",
      "0.768062 (0.005783) with: {'batch_size': 10, 'hiddenLayers': 3, 'neurons': 300}\n",
      "0.766008 (0.003554) with: {'batch_size': 10, 'hiddenLayers': 3, 'neurons': 400}\n",
      "0.651094 (0.106841) with: {'batch_size': 10, 'hiddenLayers': 5, 'neurons': 20}\n",
      "0.736585 (0.015654) with: {'batch_size': 10, 'hiddenLayers': 5, 'neurons': 50}\n",
      "0.745323 (0.003070) with: {'batch_size': 10, 'hiddenLayers': 5, 'neurons': 100}\n",
      "0.758623 (0.010665) with: {'batch_size': 10, 'hiddenLayers': 5, 'neurons': 200}\n",
      "0.765929 (0.007581) with: {'batch_size': 10, 'hiddenLayers': 5, 'neurons': 300}\n",
      "0.761363 (0.004058) with: {'batch_size': 10, 'hiddenLayers': 5, 'neurons': 400}\n",
      "0.730515 (0.006870) with: {'batch_size': 32, 'hiddenLayers': 1, 'neurons': 20}\n",
      "0.742838 (0.005826) with: {'batch_size': 32, 'hiddenLayers': 1, 'neurons': 50}\n",
      "0.743509 (0.002058) with: {'batch_size': 32, 'hiddenLayers': 1, 'neurons': 100}\n",
      "0.755148 (0.007184) with: {'batch_size': 32, 'hiddenLayers': 1, 'neurons': 200}\n",
      "0.754319 (0.007307) with: {'batch_size': 32, 'hiddenLayers': 1, 'neurons': 300}\n",
      "0.756541 (0.005184) with: {'batch_size': 32, 'hiddenLayers': 1, 'neurons': 400}\n",
      "0.673672 (0.014966) with: {'batch_size': 32, 'hiddenLayers': 2, 'neurons': 20}\n",
      "0.729424 (0.000366) with: {'batch_size': 32, 'hiddenLayers': 2, 'neurons': 50}\n",
      "0.747944 (0.004024) with: {'batch_size': 32, 'hiddenLayers': 2, 'neurons': 100}\n",
      "0.751873 (0.005639) with: {'batch_size': 32, 'hiddenLayers': 2, 'neurons': 200}\n",
      "0.755004 (0.005014) with: {'batch_size': 32, 'hiddenLayers': 2, 'neurons': 300}\n",
      "0.754157 (0.005860) with: {'batch_size': 32, 'hiddenLayers': 2, 'neurons': 400}\n",
      "0.691853 (0.020496) with: {'batch_size': 32, 'hiddenLayers': 3, 'neurons': 20}\n",
      "0.738790 (0.009785) with: {'batch_size': 32, 'hiddenLayers': 3, 'neurons': 50}\n",
      "0.743661 (0.003927) with: {'batch_size': 32, 'hiddenLayers': 3, 'neurons': 100}\n",
      "0.752668 (0.004046) with: {'batch_size': 32, 'hiddenLayers': 3, 'neurons': 200}\n",
      "0.755143 (0.006909) with: {'batch_size': 32, 'hiddenLayers': 3, 'neurons': 300}\n",
      "0.759860 (0.004829) with: {'batch_size': 32, 'hiddenLayers': 3, 'neurons': 400}\n",
      "0.639220 (0.058696) with: {'batch_size': 32, 'hiddenLayers': 5, 'neurons': 20}\n",
      "0.717462 (0.027184) with: {'batch_size': 32, 'hiddenLayers': 5, 'neurons': 50}\n",
      "0.731261 (0.009938) with: {'batch_size': 32, 'hiddenLayers': 5, 'neurons': 100}\n",
      "0.750061 (0.007074) with: {'batch_size': 32, 'hiddenLayers': 5, 'neurons': 200}\n",
      "0.751988 (0.005357) with: {'batch_size': 32, 'hiddenLayers': 5, 'neurons': 300}\n",
      "0.754857 (0.006146) with: {'batch_size': 32, 'hiddenLayers': 5, 'neurons': 400}\n",
      "0.703845 (0.009510) with: {'batch_size': 64, 'hiddenLayers': 1, 'neurons': 20}\n",
      "0.721097 (0.004470) with: {'batch_size': 64, 'hiddenLayers': 1, 'neurons': 50}\n",
      "0.733275 (0.002192) with: {'batch_size': 64, 'hiddenLayers': 1, 'neurons': 100}\n",
      "0.737561 (0.002257) with: {'batch_size': 64, 'hiddenLayers': 1, 'neurons': 200}\n",
      "0.740394 (0.007474) with: {'batch_size': 64, 'hiddenLayers': 1, 'neurons': 300}\n",
      "0.741385 (0.001926) with: {'batch_size': 64, 'hiddenLayers': 1, 'neurons': 400}\n",
      "0.686312 (0.033474) with: {'batch_size': 64, 'hiddenLayers': 2, 'neurons': 20}\n",
      "0.714577 (0.015304) with: {'batch_size': 64, 'hiddenLayers': 2, 'neurons': 50}\n",
      "0.736724 (0.005893) with: {'batch_size': 64, 'hiddenLayers': 2, 'neurons': 100}\n",
      "0.736781 (0.007234) with: {'batch_size': 64, 'hiddenLayers': 2, 'neurons': 200}\n",
      "0.744192 (0.004226) with: {'batch_size': 64, 'hiddenLayers': 2, 'neurons': 300}\n",
      "0.745745 (0.010450) with: {'batch_size': 64, 'hiddenLayers': 2, 'neurons': 400}\n",
      "0.625566 (0.059781) with: {'batch_size': 64, 'hiddenLayers': 3, 'neurons': 20}\n",
      "0.692605 (0.019996) with: {'batch_size': 64, 'hiddenLayers': 3, 'neurons': 50}\n",
      "0.719977 (0.005522) with: {'batch_size': 64, 'hiddenLayers': 3, 'neurons': 100}\n",
      "0.728666 (0.007382) with: {'batch_size': 64, 'hiddenLayers': 3, 'neurons': 200}\n",
      "0.742395 (0.001533) with: {'batch_size': 64, 'hiddenLayers': 3, 'neurons': 300}\n",
      "0.743949 (0.009184) with: {'batch_size': 64, 'hiddenLayers': 3, 'neurons': 400}\n",
      "0.557312 (0.081051) with: {'batch_size': 64, 'hiddenLayers': 5, 'neurons': 20}\n",
      "0.659140 (0.025783) with: {'batch_size': 64, 'hiddenLayers': 5, 'neurons': 50}\n",
      "0.668871 (0.017025) with: {'batch_size': 64, 'hiddenLayers': 5, 'neurons': 100}\n",
      "0.717744 (0.013362) with: {'batch_size': 64, 'hiddenLayers': 5, 'neurons': 200}\n",
      "0.736497 (0.002348) with: {'batch_size': 64, 'hiddenLayers': 5, 'neurons': 300}\n",
      "0.745604 (0.008221) with: {'batch_size': 64, 'hiddenLayers': 5, 'neurons': 400}\n"
     ]
    }
   ],
   "source": [
    "gridSearchSummary('grid_result', 'accuracy') # Note that it is AUC that is printed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best combination of the chosen number of hidden layers and neuron numbers is one hidden layer and two hundred neurons. \n",
    "\n",
    "A batch size of 10 is the best among the chosen batch sizes.\n",
    "\n",
    "Next we apply the optimal combination of batch size and neuron number from the crossvalidation train a model on the full training set. The model based on the full training set will then be applied to measure the accuracy on predictions on the test set.  \n",
    "\n",
    "### FItting the best model: early stopping\n",
    "We see from the above that the validation accuracy declines for the highest number of neurons. The decline in validation accuracy is a sign of overfitting. In order to avoid overfitting we use a methods for \"early stopping\". Early stopping stops the simulations when the validation set performance has dropped a user given number of times in a row. In order for the model to be able to escape local minima, we allo the validation accuracy to drop a few times before breaking. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs before early stopping:  7\n"
     ]
    }
   ],
   "source": [
    "hiddenLayers, neurons =  grid_result.best_params_['hiddenLayers'], grid_result.best_params_['neurons']\n",
    "batch_size = 10\n",
    "\n",
    "model = KerasClassifier(build_fn=createModel, verbose=0, neurons =neurons, hiddenLayers = hiddenLayers)\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                             min_delta=0,\n",
    "                                             patience=2, # argument represents the number of epochs before stopping once your loss starts to increase (stops improving)\n",
    "                                             verbose=0, \n",
    "                                             mode='auto')]#,\n",
    "                                             #restore_best_weights=True)] # Use best model\n",
    "history = model.fit(XTrain,\n",
    "                        Y_train_onehot,\n",
    "                        epochs=15, \n",
    "                        batch_size=batch_size,\n",
    "                        validation_data=[XTest, Y_test_onehot],\n",
    "                        callbacks = callbacks)\n",
    "\n",
    "print('Number of epochs before early stopping: ', len(history.history['loss']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrices, accuracy scores and AUC-numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n",
      "\n",
      "Training Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.65 0.35]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8266\n",
      "\n",
      "Train AUC: \n",
      " 0.6532070459976378\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.68 0.32]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8144\n",
      "\n",
      "TestAUC: \n",
      " 0.6383047796498249\n"
     ]
    }
   ],
   "source": [
    "confusionArrayNN = createConfusionMatrix('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about a third of the defaulting customers are correctly predicted. However, the performance is considerablt better than for logistic regression, where only a fourth of the customers with default was correctly predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok accuracy. Not impressing performance when it compes to predicting the defaults. Only a 3rd of the defaults in the test set is correctly predicted. <br>\n",
    "\n",
    "Yeh and Lien (2009) get: <br>\n",
    "Training accuracy: 0.81<br>\n",
    "Training AUC: 0.55 <br>\n",
    "Testing accuracy: 0.83<br>\n",
    "Testing AUC: 0.54 <br>\n",
    "\n",
    "We see that we get the accuracy the the same level as Yeh and Lien (2009), but the AUC is better. However, it is unclear wheteher it acutally is AUC Yeh and Lien (2009) applies, as they call it area ratio.<br>\n",
    "\n",
    "Pyzhov and Pyzhov (2017) get about the same acuracy as we do, but higher AUCs.\n",
    "\n",
    "# Principal component analyses\n",
    "We will explore the effects of training the network with principcal components. For many of the networks we do not expect the introduction of principcal components to improve the performance considerably. The difference between training and testing accuracy is small for many of the networks, indicating that there is little overfitting. Maybe for the network setuos where there are larger deviations between training and testing accuracy, the networks with mutiple hidden layers, there can be gains from introducing principcal components. \n",
    "\n",
    "We use the principal components that explain 95 per cent of total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nfrom sklearn.decomposition import PCA\\n\\n\\n\\npca = PCA(n_components = 0.95)\\nXreduced = pca.fit_transform(X)\\nprint(pca.explained_variance_ratio_)\\nprint(np.sum(pca.explained_variance_ratio_))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n",
    "pca = PCA(n_components = 0.95)\n",
    "Xreduced = pca.fit_transform(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrainingShare = 0.5 \\nXTrain, XTest, yTrain, yTest=train_test_split(Xreduced, y, train_size=trainingShare,                                               test_size = 1-trainingShare)\\nY_train_onehot, Y_test_onehot = to_categorical(yTrain), to_categorical(yTest)\\nmodel = tf.keras.Sequential()\\nmodel.add(tf.keras.layers.Dense(50, activation='relu', input_dim=XTrain.shape[1]))\\nmodel.add(tf.keras.layers.Dense(50, activation='relu'))\\nmodel.add(tf.keras.layers.Dense(50, activation='relu'))\\nmodel.add(tf.keras.layers.Dense(50, activation='relu'))\\nmodel.add(tf.keras.layers.Dense(50, activation='relu'))\\nmodel.add(tf.keras.layers.Dense(Y_train_onehot.shape[1], activation='softmax'))\\nmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\\nprint(model.summary())\\n\\ncallbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\\n                                             min_delta = 0,\\n                                             patience=5,\\n                                             verbose=0,\\n                                             mode='auto')]\\n\\n\\nhistory = model.fit(XTrain,\\n                    Y_train_onehot, \\n                    epochs=100, \\n                    batch_size=30,\\n                    validation_data=[XTest, Y_test_onehot],\\n                    callbacks = callbacks)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "trainingShare = 0.5 \n",
    "XTrain, XTest, yTrain, yTest=train_test_split(Xreduced, y, train_size=trainingShare, \\\n",
    "                                              test_size = 1-trainingShare)\n",
    "Y_train_onehot, Y_test_onehot = to_categorical(yTrain), to_categorical(yTest)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu', input_dim=XTrain.shape[1]))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(Y_train_onehot.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                             min_delta = 0,\n",
    "                                             patience=5,\n",
    "                                             verbose=0,\n",
    "                                             mode='auto')]\n",
    "\n",
    "\n",
    "history = model.fit(XTrain,\n",
    "                    Y_train_onehot, \n",
    "                    epochs=100, \n",
    "                    batch_size=30,\n",
    "                    validation_data=[XTest, Y_test_onehot],\n",
    "                    callbacks = callbacks)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both training and testing accuracy is reduced when using Principal components as predictors instead of all of the original features. However, we also observe that the difference between training and validation accuracy is smaller when using principal components as predictors instead of all the features from the original data set.\n",
    "\n",
    "## Kernel PCA\n",
    "We will try Sci-Kit learn's kernel PCA method. Kernel PCA, kPca, is a PCA-method that allows for non-linearity. <mark> More about this!\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.decomposition import KernelPCA, TruncatedSVD\\nkPCA = KernelPCA(n_components=2, kernel='rbf', gamma=10) #0.04\\n#kPCA = TruncatedSVD(n_components=5, algorithm='arpack')\\nX_reduced = kPCA.fit_transform(X)\\nprint(kPCA.explained_variance_ratio_)\\nprint(np.sum(kPCA.explained_variance_ratio_))\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.decomposition import KernelPCA, TruncatedSVD\n",
    "kPCA = KernelPCA(n_components=2, kernel='rbf', gamma=10) #0.04\n",
    "#kPCA = TruncatedSVD(n_components=5, algorithm='arpack')\n",
    "X_reduced = kPCA.fit_transform(X)\n",
    "print(kPCA.explained_variance_ratio_)\n",
    "print(np.sum(kPCA.explained_variance_ratio_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kPCA did not work. It gave memory error.\n",
    "\n",
    "# Support Vector Machines (SVM)\n",
    "We will now apply the SVM classifier to make the classification. We start by running the standard SVM estimator, and then we try alternative methods that potentially increase accuracy in the presence of non-linearity in the data. By \"non-linearity\" we mean that the labels cannot be separated by a linear classification plane (line in 2D, 2D plane in 3D, hyperplane for higher dimensions than 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{'C':np.logspace(-3,3,7)}]\n",
    "\n",
    "svmNormal = LinearSVC(loss='hinge')\n",
    "#svmNormal = SVC(kernel='linear',probability=True) # In order to use soft voting for ensamble classifiser. SLOOOW!\n",
    "\n",
    "folds = 5\n",
    "scoring = ['accuracy', 'roc_auc']\n",
    "\n",
    "gridSearchSVMNormal = GridSearchCV(svmNormal, cv = folds, param_grid=parameters, scoring=scoring, refit='roc_auc')\n",
    "SVMNormalCVResult = gridSearchSVMNormal.fit(XTrain, yTrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.709996 using {'C': 0.1}\n",
      "0.692395 (0.007908) with: {'C': 0.001}\n",
      "0.707004 (0.011286) with: {'C': 0.01}\n",
      "0.709996 (0.010766) with: {'C': 0.1}\n",
      "0.703089 (0.008811) with: {'C': 1.0}\n",
      "0.697648 (0.016885) with: {'C': 10.0}\n",
      "0.670020 (0.025418) with: {'C': 100.0}\n",
      "0.579618 (0.095466) with: {'C': 1000.0}\n"
     ]
    }
   ],
   "source": [
    "gridSearchSummary('SVMNormalCVResult', 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n",
      "\n",
      "Training Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.75 0.25]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8146666666666667\n",
      "\n",
      "Train AUC: \n",
      " 0.6125365664967218\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.77 0.23]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8043333333333333\n",
      "\n",
      "TestAUC: \n",
      " 0.6003151610373783\n"
     ]
    }
   ],
   "source": [
    "confusionArraySVMNormal = createConfusionMatrix('SVMNormalCVResult')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear SVM the accuracies look very similar to the accuracies from logistic regression and neural networks. About a fourth of the customers with problem loans is predicted correctly with standard SVM. \n",
    "\n",
    "SVM stands out from the other mentioned methods in that the testing accuracy and AUC is a little higher than the training accuracy, which is unusual.\n",
    "\n",
    "### Polynomial SVM\n",
    "Increasing the complexity by introducing polynomial variables may increase the quality of the separation. We will not perform an polynomial SVM-estimation where we use second degree polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.pipeline import Pipeline\\nfrom sklearn.preprocessing import PolynomialFeatures\\n\\npolynomial_svm_clf = Pipeline([\\n        (\"poly_features\", PolynomialFeatures(degree=2)),\\n        (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", random_state=42))\\n    ])\\n\\npolynomial_svm_clf.fit(XTrain, yTrain.ravel())\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomial_svm_clf = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=2)),\n",
    "        (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", random_state=42))\n",
    "    ])\n",
    "\n",
    "polynomial_svm_clf.fit(XTrain, yTrain.ravel())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusionArraySVMPoly = createConfusionMatrix('polynomial_svm_clf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resuls with the 2nd degree polynomial are worse than with the normal SVM. Only a fourth of the customers with defauls is correctly predicted. Higher degree polynomial might work better. \n",
    "### SVM: Polynomial kernel\n",
    "The computational cost quickly becomes large for higher degree polynomials. \n",
    "\n",
    "A remedy is to use the so-called Kernel trick to effectively apply higher degree polynomials. With the kernel-trick we get higher degree polynomials without the extra computational cost!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.svm import SVC\\nfrom sklearn.model_selection import GridSearchCV\\n\\nsvmPolynomialKernel = SVC(kernel='poly')\\nparameters = [{'degree': np.array((2,3)), 'C': [1.0]},\\n              {'C':np.logspace(-1,1,3), 'degree': [3]}]\\nscoring = ['accuracy', 'roc_auc']\\nfolds = 5\\nsmvPolyKernelGridSearch = GridSearchCV(svmPolynomialKernel, cv = folds, param_grid=parameters, scoring=scoring,\\n                                       refit='roc_auc')\\nsmvPolyKernelGridSearchResult = smvPolyKernelGridSearch.fit(XTrain, yTrain.ravel())\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svmPolynomialKernel = SVC(kernel='poly')\n",
    "parameters = [{'degree': np.array((2,3)), 'C': [1.0]},\n",
    "              {'C':np.logspace(-1,1,3), 'degree': [3]}]\n",
    "scoring = ['accuracy', 'roc_auc']\n",
    "folds = 5\n",
    "smvPolyKernelGridSearch = GridSearchCV(svmPolynomialKernel, cv = folds, param_grid=parameters, scoring=scoring,\n",
    "                                       refit='roc_auc')\n",
    "smvPolyKernelGridSearchResult = smvPolyKernelGridSearch.fit(XTrain, yTrain.ravel())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridSearchSummary('smvPolyKernelGridSearchResult', 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three degrees works better than ten degrees. The AUC is higher for three degrees than for ten degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smvPolyKernelGridSearchResult.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusionArraySvmKernel = createConfusionMatrix('smvPolyKernelGridSearchResult')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a gain increasing the degree from two, which we used with standard polynomial SVM, to three, which was the best degree found with polynomial kernel. The result is close to the result for standard SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM: Gaussian RBF Kernel\n",
    "Another kernel method is the so-called Gaussian Radial Basis Function (RBF) method. Following Geron (2017) p. 153, the following transformation is used $$\\phi_\\gamma (\\hat{x}, l) = \\exp(-\\gamma ||\\hat{x} - l||^2), $$\n",
    "\n",
    "where $l$ is the position of so-called landmarks. One often applies landmarks for every instancein the data set. This increases the number of features from the original feature number to the number of instances. The new variables represents a higher dimensional space compared to the original feature space, and the chance that the new features are linearly separable is increased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{'gamma': np.logspace(-1,2,4), 'C': np.logspace(-1,1,3)}]\n",
    "#parameters = [{'gamma': np.array((.1, 1)), 'C': np.array((.001, 1000))}]\n",
    "#parameters = [{'gamma': np.array((.1, 1))}]\n",
    "\n",
    "folds = 5\n",
    "svmKernel = SVC(kernel='rbf', probability=True, random_state=0)\n",
    "scoring = ['accuracy', 'roc_auc']\n",
    "svmKernelGridSearch = GridSearchCV(svmKernel, cv = folds, param_grid=parameters, scoring=scoring, refit='roc_auc')\n",
    "svmKernelGridSearchResult = svmKernelGridSearch.fit(XTrain, yTrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svmKernelGridSearchResult.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.719677 using {'C': 0.1, 'gamma': 0.1}\n",
      "0.719677 (0.009401) with: {'C': 0.1, 'gamma': 0.1}\n",
      "0.681363 (0.013478) with: {'C': 0.1, 'gamma': 1.0}\n",
      "0.616492 (0.017548) with: {'C': 0.1, 'gamma': 10.0}\n",
      "0.549038 (0.012137) with: {'C': 0.1, 'gamma': 100.0}\n",
      "0.718601 (0.011608) with: {'C': 1.0, 'gamma': 0.1}\n",
      "0.677693 (0.014450) with: {'C': 1.0, 'gamma': 1.0}\n",
      "0.616857 (0.017853) with: {'C': 1.0, 'gamma': 10.0}\n",
      "0.552527 (0.012198) with: {'C': 1.0, 'gamma': 100.0}\n",
      "0.704258 (0.009608) with: {'C': 10.0, 'gamma': 0.1}\n",
      "0.653310 (0.016532) with: {'C': 10.0, 'gamma': 1.0}\n",
      "0.612412 (0.013955) with: {'C': 10.0, 'gamma': 10.0}\n",
      "0.553383 (0.011699) with: {'C': 10.0, 'gamma': 100.0}\n"
     ]
    }
   ],
   "source": [
    "gridSearchSummary('svmKernelGridSearchResult', 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n",
      "\n",
      "Training Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.71 0.29]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8198\n",
      "\n",
      "Train AUC: \n",
      " 0.6298058949878448\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.72 0.28]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8085333333333333\n",
      "\n",
      "TestAUC: \n",
      " 0.6209928082448268\n"
     ]
    }
   ],
   "source": [
    "confusionArrayRBFKernel = createConfusionMatrix('svmKernelGridSearchResult')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test AUC is higer than with standard SVM and polynomial SVM. For the Gaussian kernel estimator, 28 per cent of the defaulted customers are predicted correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision trees: Theory\n",
    "Decision trees are binary trees, meaning that one node is split into two nodes. At the top of the tree there is one node. The top node is split into two nodes. The split is done by the inspection of one feature. A threshold for the feature is chosen. If an instance has a value lower than the threshold, it belongs to node 1. If the instance has a value higher than the threshold, it belongs to the other node. \n",
    "\n",
    "The feature and threshold value for the given feature is decided by so that the resulting nodes are as homogenuous as possible with respect to class type. The (dis)similarity of the instances is called _impurity_. There are several measures of impurity. The Gini-coefficient is one of the impurity measures, and is given by $$G_i = 1 - \\sum_{k=1}^n (\\frac{N_k}{N_{node}})^2,$$ where $N_k$ is the number of class $k$ instances in node $i$ and $N_{node}$ is the number of total instances in node $i$. \n",
    "\n",
    "Example: Say a node is split with respect to a feature so that all the instances in one of the nodes are of the same class. Then the Gini-index becomes 0. There is no heteregenity in the node. \n",
    "\n",
    "The example above does not necessarely picture a good decision. If the impurity in the other node is high, the tree may  not be so well designed. Hence the optimal combination of feature and threshold must take into account both noeds. The feature and threshold are chosen so that the weighted impurity of the nodes is minimized: $$\\min_{\\mathrm{feature, threshold}} \\{\\frac{m_i}{m} G_i + \\frac{m-m_i}{m} G_j \\},$$\n",
    "\n",
    "where $m_i$ is the number of instances in node one, $m$ is the total number of instances, $G_i$ is the impurity in node one and the $G_j$ is the impurity in node two.\n",
    "\n",
    "The decision tree optimizes the feature and threshold values locally, so the algorithm is sensitive to local optima. The determination of a feature-threshold combo at one point in the tree does not take into account what happens further down in the tree than the next two nodes determined by the given threshold. It is possible that a sub-optimal local choise of feature-threshold can give globally lower total impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision trees: Sci-Kit learn\n",
    "As for all the other methods, we avoid overfitting by utlizing Sci-Kit learns GridSearchCV method. As all methods, decision trees can overfit. We limit the potential for overfitting by the use of hyperparamters. We fine tune the hyperparamters \"max_depth\" and \"min_samples_per_leaf\". Max_depth can range from 1 to the numnber of features. Using all features typically lead to a model that is sensitive to new data, so that it generalizes badly (overfitting). By restricting the minimum number of samples per leaf, adjusting min_samples_per_leaf, we make sure that every leaf must be of a minimum size. Small leafs are typically uncertain, since they are based only on a few observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "folds = 5\n",
    "features = df.shape[1] - 1\n",
    "max_depth = [3,4, 5, 6, features]\n",
    "min_samples_leaf = np.arange(2,14,2)\n",
    "parameters = [{'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf}]\n",
    "scoring = ['accuracy', 'roc_auc']\n",
    "gsDT = GridSearchCV(dt, param_grid=parameters, scoring=scoring, refit='roc_auc')\n",
    "gsDTResult = gsDT.fit(XTrain, yTrain.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.751622 using {'max_depth': 5, 'min_samples_leaf': 12}\n",
      "0.730777 (0.004474) with: {'max_depth': 3, 'min_samples_leaf': 2}\n",
      "0.731062 (0.004359) with: {'max_depth': 3, 'min_samples_leaf': 4}\n",
      "0.730888 (0.004425) with: {'max_depth': 3, 'min_samples_leaf': 6}\n",
      "0.730888 (0.004425) with: {'max_depth': 3, 'min_samples_leaf': 8}\n",
      "0.730888 (0.004425) with: {'max_depth': 3, 'min_samples_leaf': 10}\n",
      "0.731002 (0.004380) with: {'max_depth': 3, 'min_samples_leaf': 12}\n",
      "0.741792 (0.004874) with: {'max_depth': 4, 'min_samples_leaf': 2}\n",
      "0.742048 (0.004946) with: {'max_depth': 4, 'min_samples_leaf': 4}\n",
      "0.742227 (0.004695) with: {'max_depth': 4, 'min_samples_leaf': 6}\n",
      "0.742281 (0.004739) with: {'max_depth': 4, 'min_samples_leaf': 8}\n",
      "0.742560 (0.004989) with: {'max_depth': 4, 'min_samples_leaf': 10}\n",
      "0.742242 (0.007559) with: {'max_depth': 4, 'min_samples_leaf': 12}\n",
      "0.749485 (0.009306) with: {'max_depth': 5, 'min_samples_leaf': 2}\n",
      "0.750355 (0.008480) with: {'max_depth': 5, 'min_samples_leaf': 4}\n",
      "0.750749 (0.007506) with: {'max_depth': 5, 'min_samples_leaf': 6}\n",
      "0.750440 (0.007886) with: {'max_depth': 5, 'min_samples_leaf': 8}\n",
      "0.750475 (0.008047) with: {'max_depth': 5, 'min_samples_leaf': 10}\n",
      "0.751622 (0.009605) with: {'max_depth': 5, 'min_samples_leaf': 12}\n",
      "0.744378 (0.009224) with: {'max_depth': 6, 'min_samples_leaf': 2}\n",
      "0.746869 (0.010338) with: {'max_depth': 6, 'min_samples_leaf': 4}\n",
      "0.749186 (0.007661) with: {'max_depth': 6, 'min_samples_leaf': 6}\n",
      "0.749202 (0.007048) with: {'max_depth': 6, 'min_samples_leaf': 8}\n",
      "0.748997 (0.008402) with: {'max_depth': 6, 'min_samples_leaf': 10}\n",
      "0.749747 (0.008888) with: {'max_depth': 6, 'min_samples_leaf': 12}\n",
      "0.623808 (0.003845) with: {'max_depth': 23, 'min_samples_leaf': 2}\n",
      "0.655471 (0.001752) with: {'max_depth': 23, 'min_samples_leaf': 4}\n",
      "0.674575 (0.001744) with: {'max_depth': 23, 'min_samples_leaf': 6}\n",
      "0.688351 (0.007474) with: {'max_depth': 23, 'min_samples_leaf': 8}\n",
      "0.693191 (0.007155) with: {'max_depth': 23, 'min_samples_leaf': 10}\n",
      "0.699970 (0.007329) with: {'max_depth': 23, 'min_samples_leaf': 12}\n"
     ]
    }
   ],
   "source": [
    "gridSearchSummary('gsDTResult', 'auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that max_depth =  5 and min_samples_leaf= 10 is the best combo of the chosen hyperparameters. Higher and lower values of both variabes are studied, indicating the best combination is close to the optimal combination for these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n",
      "\n",
      "Training Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.63 0.37]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8284\n",
      "\n",
      "Train AUC: \n",
      " 0.6647103048680738\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.95 0.05]\n",
      " [0.64 0.36]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8181333333333334\n",
      "\n",
      "TestAUC: \n",
      " 0.6536075639875488\n"
     ]
    }
   ],
   "source": [
    "confusionArrayDT = createConfusionMatrix('gsDTResult')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not impressing. Still we predict the customers with defaul wrongly more often than correctly. However, compared to the other methods, the decision tree is among the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests\n",
    "Random forests is the result of combining bootstrapping, or \"bagging\" for bootstrap aggregating as it is called in the machine learning litterature,  with decision trees. Here is the algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For bootstrap in totalBootstraps:\n",
    "    \n",
    "    1. Draw a training set with replacement from the full training set.\n",
    "    2. Estimate a model from the drawn training set.\n",
    "    3. Calculate the performance of the estimated model on the non-drawn observations.\n",
    "\n",
    "4. Calculate the mean test score over all models. (Gives an indication of testing set performance).\n",
    "5. Make predictions on the testing set using all models.\n",
    "6. Choose the class eighter has most model predictions (hard classifier) or the class with highest average probibility (soft classifier).\n",
    "    \n",
    "There is an additional feature with random forrests that is not used for decision trees. In random forests, a random subset of predictors are chosen as candidates for variable to split data set against. The random subsets has the implication that not all the trees in the forest has the same dominating feature at the top of the tree, making the trees more heterogenuous. More heterogenuous trees has the potential of making the trees less dependent. Less dependent trees increases the predicive accuracy of the random forest estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests: Sci-kit learn\n",
    "We apply the same hyperparameters that was found to be best for the random tree estimator. It is reasonable to apply the same hyperparameters for random forests as for random trees, since the trees that makes up the forest are the same trees that was trained in the decision tree scenario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/k/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "n_estimators=500\n",
    "min_samples_leaf = gsDTResult.best_params_['min_samples_leaf']\n",
    "max_depth = gsDTResult.best_params_['max_depth']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_depth=max_depth,\n",
    "                           random_state=1)\n",
    "#rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "rfResults = rf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n",
      "\n",
      "Training Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.65 0.35]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8295333333333333\n",
      "\n",
      "Train AUC: \n",
      " 0.6580565253341818\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.67 0.33]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8157333333333333\n",
      "\n",
      "TestAUC: \n",
      " 0.642229708571287\n"
     ]
    }
   ],
   "source": [
    "confusionArrayRF = createConfusionMatrix('rfResults')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is pretty similar to the random tree performance. We expected a higher performance for random forests.\n",
    "\n",
    "## Random forests: hyperparameters\n",
    "Next we check wheter the random forest performs better with another set of hyperparameter values than what was found to be best for decision trees.\n",
    "\n",
    "When identifying the best hyperparameters for Random forests, we do not need to use GridSearcCV. For random forests, which applies bootstrapping, we can make Sci-Kit learn report the results of predictions by the different models on the observations that was not drawn as training set. The observations that is not drawn to be in the training set is the so-called out-of-bag (oob) observations. The oob observations performs as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "features = df.shape[1] - 1\n",
    "max_depthList = [3,4, 5, 6, features]\n",
    "min_samples_leafList = np.arange(2,14,2)\n",
    "n_estimators = 500\n",
    "#parameters = [{'max_depth': max_depth, 'min_samples_leaf': min_samples_leaf}]\n",
    "#models = np.zeros(len(max_depthList)*len(min_samples_leafList), dtype=object)\n",
    "models = np.zeros((len(max_depthList), len(min_samples_leafList)), dtype=object)\n",
    "oobs = np.zeros((len(max_depthList), len(min_samples_leafList)))\n",
    "counter = 0\n",
    "for i, max_depth in enumerate(max_depthList):\n",
    "    for j, min_samples_leaf in enumerate(min_samples_leafList):\n",
    "        rfHP =  RandomForestClassifier(n_estimators=n_estimators, min_samples_leaf=min_samples_leaf, max_depth=max_depth,\n",
    "                                      oob_score=True, random_state=1)\n",
    "        rfHP.fit(XTrain, yTrain.ravel())\n",
    "        models[i,j] = rfHP\n",
    "        #oobs[counter] = roc_auc_score(yTrain.ravel(),rfHP.oob_prediction) #rfHP.oob_score_\n",
    "        pred_train = rfHP.oob_decision_function_[:, 1] #https://datascience.stackexchange.com/questions/13151/randomforestclassifier-oob-scoring-method\n",
    "        oobs[i,j] = roc_auc_score(yTrain.ravel(), pred_train)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best max_depth:  23\n",
      "Best min_samples_leaf:  10\n",
      "Best oob AUC:  0.7801985182246344\n",
      "\n",
      "###################  Training  ###############\n",
      "\n",
      "Training Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.57 0.43]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8519333333333333\n",
      "\n",
      "Train AUC: \n",
      " 0.7005753094947953\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.95 0.05]\n",
      " [0.65 0.35]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8155333333333333\n",
      "\n",
      "TestAUC: \n",
      " 0.648654852708037\n"
     ]
    }
   ],
   "source": [
    "from numpy import unravel_index\n",
    "bestIndexRFHyper = unravel_index(oobs.argmax(), oobs.shape)\n",
    "print('Best max_depth: ', max_depthList[bestIndexRFHyper[0]])\n",
    "print('Best min_samples_leaf: ', min_samples_leafList[bestIndexRFHyper[1]])\n",
    "print('Best oob AUC: ', oobs[bestIndexRFHyper])\n",
    "rfHyperFinal = models[bestIndexRFHyper]\n",
    "confusionArrayRFHyperparameter = createConfusionMatrix('rfHyperFinal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best hyperparameter combo differes between decision trees and random forests. For decision trees the combo 5 and 10 for max_depth and min_samples_leaf gave best results, while for random forests the best compbo is 23 and 12. This was unexpected, since the forest consists of the same type of trees as the decision tree classifier. A possible explanation for the discrapency in optimal hyperparameter combos between decision trees and forests could be that the validation set sizes differs. With decision trees we applied 5-fold cross-validation, implying that twenty per cent of the training data was used for validation. For Random forests about 35 per cent of the training data is on average used for validation.\n",
    "\n",
    "The results are better than when applying the hyperparameter combo that was best for decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble learning\n",
    "Enemble learning is when we combine different estimators. Ensemble learning has the potential to reudce both bias and variance. Predictors that perform poorly individually can when combined perform well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.ensemble import VotingClassifier\\n\\n#('svmPoly', polynomial_svm_clf),\\n#('smvPolyKernel', smvPolyKernelGridSearch),\\n# nn model\\n#('svm', gridSearchSVMNormal),\\nvotingClf = VotingClassifier(\\n                            estimators = [('lr', gridSearch), \\n                                          ('svmKernel', svmKernelGridSearch),\\n                                          ('rf', rfHyperFinal)],\\n                            voting='hard')\\nvotingClf.fit(XTrain, yTrain)\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#('svmPoly', polynomial_svm_clf),\n",
    "#('smvPolyKernel', smvPolyKernelGridSearch),\n",
    "# nn model\n",
    "#('svm', gridSearchSVMNormal),\n",
    "votingClf = VotingClassifier(\n",
    "                            estimators = [('lr', gridSearch), \n",
    "                                          ('svmKernel', svmKernelGridSearch),\n",
    "                                          ('rf', rfHyperFinal)],\n",
    "                            voting='hard')\n",
    "votingClf.fit(XTrain, yTrain)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusionArrayEnsemble= createConfusionMatrix('votingClf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hard vote does not perform better than the best individual classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamle: Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.ensemble import VotingClassifier\\n\\n#('svmPoly', polynomial_svm_clf),\\n#('smvPolyKernel', smvPolyKernelGridSearch),\\n# nn model\\n#('svm', gridSearchSVMNormal),\\nvotingClf = VotingClassifier(\\n                            estimators = [('lr', gridSearch), \\n                                          ('svmKernel', svmKernelGridSearch),\\n                                          ('rf', rfHyperFinal)],\\n                            voting='soft')\\nvotingClf.fit(XTrain, yTrain)\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#('svmPoly', polynomial_svm_clf),\n",
    "#('smvPolyKernel', smvPolyKernelGridSearch),\n",
    "# nn model\n",
    "#('svm', gridSearchSVMNormal),\n",
    "votingClf = VotingClassifier(\n",
    "                            estimators = [('lr', gridSearch), \n",
    "                                          ('svmKernel', svmKernelGridSearch),\n",
    "                                          ('rf', rfHyperFinal)],\n",
    "                            voting='soft')\n",
    "votingClf.fit(XTrain, yTrain)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusionArrayEnsemble= createConfusionMatrix('votingClf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The soft vote performs about the same as the hard voting classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble: With NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.ensemble import VotingClassifier\\n\\n#('svmPoly', polynomial_svm_clf),\\n#('smvPolyKernel', smvPolyKernelGridSearch),\\n# nn model\\n#('svm', gridSearchSVMNormal),\\nvotingClfNN = VotingClassifier(\\n                            estimators = [('lr', gridSearch), \\n                                          ('svmKernel', svmKernelGridSearch),\\n                                          ('rf', rfHyperFinal),\\n                                          ('nn', model)],\\n                            voting='soft')\\nvotingClfNN.fit(XTrain, yTrain.ravel())\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#('svmPoly', polynomial_svm_clf),\n",
    "#('smvPolyKernel', smvPolyKernelGridSearch),\n",
    "# nn model\n",
    "#('svm', gridSearchSVMNormal),\n",
    "votingClfNN = VotingClassifier(\n",
    "                            estimators = [('lr', gridSearch), \n",
    "                                          ('svmKernel', svmKernelGridSearch),\n",
    "                                          ('rf', rfHyperFinal),\n",
    "                                          ('nn', model)],\n",
    "                            voting='soft')\n",
    "votingClfNN.fit(XTrain, yTrain.ravel())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusionArrayEnsemble= createConfusionMatrix('votingClfNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including the neural networks classifier worsens the ensamble classifier preidiction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the esemble of the logistic regressor and the SVM regressor are poor. The ensemble result is worse than the results of both the estimatores making up the ensemble.\n",
    "\n",
    "In the above ensemble I used the best combination of hyperparameters for the sub-estimators from the grid searches. I will now try to not use the grid search hyperparameters in order to see if the optimal hyperparameters change when using ensemble learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensamble: No re-training\n",
    "Sci-Kit learn's votingClassifiers, which we used above, retrains all the sub-classifiers. Hence the hyperparameter tuning done earlier is missed. In order to keep the hyperparameters that were shown to be best for the individual classifiers, we will here apply a method that allows for pre-trained classifiers and voting.\n",
    "\n",
    "### Without NN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.67 0.33]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8298666666666666\n",
      "\n",
      "Train AUC: \n",
      " 0.6505607208040358\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.7  0.3 ]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8122\n",
      "\n",
      "TestAUC: \n",
      " 0.6305442658560008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[gridSearch, svmKernelGridSearch, rfHyperFinal], \n",
    "                              weights=[1,1,1],\n",
    "                              refit=False, \n",
    "                              voting='soft')\n",
    "eclf.fit(XTrain, yTrain)\n",
    "confusionArrayEnsemble= createConfusionMatrix('eclf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is exactly the same as when using Sci-Kit's votingClassifer. Hence it looks like the voting classifier retrains the original classifier instances too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WIth NN class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.66 0.34]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8307333333333333\n",
      "\n",
      "Train AUC: \n",
      " 0.6541985923730653\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.69 0.31]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8131333333333334\n",
      "\n",
      "TestAUC: \n",
      " 0.6330485822352755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "eclf = EnsembleVoteClassifier(clfs=[gridSearch, svmKernelGridSearch, rfHyperFinal, model], \n",
    "                              weights=[1,1,1, 1],\n",
    "                              refit=False, \n",
    "                              voting='soft')\n",
    "eclf.fit(XTrain, yTrain)\n",
    "confusionArrayEnsemble= createConfusionMatrix('eclf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when we use the pre-fitted models that include neural networks, the performance is better than when all classifiers are refitted. Since the results were identical with Sci-Kit and mlxtend when the neural network was not included, it seems like the neural network is treated differently with regards to re-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble: All estimators. Hard vote (because of SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###################  Training  ###############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Confusion matrix: \n",
      " [[0.97 0.03]\n",
      " [0.68 0.32]]\n",
      "\n",
      "Training Accuracy score: \n",
      " 0.8278666666666666\n",
      "\n",
      "Train AUC: \n",
      " 0.644215715033042\n",
      "\n",
      "###################  Testing  ###############\n",
      "\n",
      "Test Confusion matrix: \n",
      " [[0.96 0.04]\n",
      " [0.71 0.29]]\n",
      "\n",
      "Test Accuracy score: \n",
      " 0.8136\n",
      "\n",
      "TestAUC: \n",
      " 0.6291209319807004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/.local/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "\n",
    "eclfAll = EnsembleVoteClassifier(clfs=[gridSearch, \n",
    "                                    gridSearchSVMNormal,\n",
    "                                    svmKernelGridSearch,\n",
    "                                    gsDT,\n",
    "                                    rfHyperFinal,\n",
    "                                    model], \n",
    "                              weights=[1,1,1, 1,1,1],\n",
    "                              refit=False, \n",
    "                              voting='hard')\n",
    "eclfAll.fit(XTrain, yTrain)\n",
    "confusionArrayEnsemble= createConfusionMatrix('eclfAll')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of the estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set(style=\"white\", context=\"notebook\", font_scale=1.5, \n",
    "            rc={\"axes.grid\": True, \"legend.frameon\": False,\n",
    "\"lines.markeredgewidth\": 1.4, \"lines.markersize\": 10})\n",
    "seaborn.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 4.5})\n",
    "#seaborn.set(style=\"ticks\", context=\"talk\")\n",
    "plt.style.use(\"dark_background\")\n",
    "seaborn.set_style({'grid.color': '.4'})\n",
    "\n",
    "confusionArrayLogreg\n",
    "#confusionArrayNN\n",
    "confusionArraySVMNormal\n",
    "confusionArraySVMPoly\n",
    "confusionArraySvmKernel\n",
    "confusionArrayRBFKernel\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "numerOfVariables = 3\n",
    "ind = np.arange(numerOfVariables)  \n",
    "width = 0.15       # the width of the bars\n",
    "rects2 = ax.bar(ind+1*width, np.asarray([confusionArrayLogreg[4], confusionArrayLogreg[5], \n",
    "                                        confusionArrayLogreg[3][1,1]]), width, color='green')\n",
    "rects3 = ax.bar(ind+2*width, np.asarray([confusionArraySVMNormal[4], confusionArraySVMNormal[5],\n",
    "                                       confusionArraySVMNormal[3][1,1]]), width, color='grey')\n",
    "rects4 = ax.bar(ind+3*width, np.asarray([confusionArraySVMPoly[4], confusionArraySVMPoly[5],\n",
    "                                       confusionArraySVMPoly[3][1,1]]), width, color='yellow')\n",
    "rects5 = ax.bar(ind+4*width, np.asarray([confusionArraySvmKernel[4], confusionArraySvmKernel[5],\n",
    "                                        confusionArraySvmKernel[3][1,1]]), width, color='r')\n",
    "rects6 = ax.bar(ind+5*width, np.asarray([confusionArrayRBFKernel[5], confusionArrayRBFKernel[5],\n",
    "                                        confusionArrayRBFKernel[3][1,1]]), width, color='b')\n",
    "rects7 = ax.bar(ind+6*width, np.asarray([confusionArrayNN[5], confusionArrayNN[5],\n",
    "                                        confusionArrayNN[3][1,1]]), width, color='magenta')\n",
    "#rects5 = ax2.bar(ind+4*width, np.asarray([beta0[4], beta1[4], beta2[4]]), width, color='pink')\n",
    "fontSize = 20\n",
    "#ax.set_title(r'$Sd(\\hat{\\beta})/\\hat{\\beta},\\;$ Noise term: %.2f' %self.noise)\n",
    "ax.set_xticks((ind + width)*1.2 )#/ 2)\n",
    "variableNames = ['Accuracy', 'AUC', 'True negative']\n",
    "ax.set_xticklabels(variableNames)\n",
    "legends = ['Logistic', 'SVM', 'SVM poly', 'SVM poly kernel', 'SVM RBF kernel', 'NN']\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(legends, loc='center left', bbox_to_anchor=(1, 0.5)\\\n",
    ", fontsize = fontSize)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "numerOfVariables = 2\n",
    "ind = np.arange(numerOfVariables)  \n",
    "width = 0.15       # the width of the bars\n",
    "rects2 = ax.bar(ind+1*width, np.asarray([confusionArrayLogreg[4], confusionArrayLogreg[5]]), width, color='green')\n",
    "rects3 = ax.bar(ind+2*width, np.asarray([confusionArraySVMNormal[4], confusionArraySVMNormal[5]]), width, color='grey')\n",
    "rects4 = ax.bar(ind+3*width, np.asarray([confusionArraySVMPoly[4], confusionArraySVMPoly[5]]), width, color='yellow')\n",
    "rects5 = ax.bar(ind+4*width, np.asarray([confusionArraySvmKernel[4], confusionArraySvmKernel[5]]), width, color='r')\n",
    "rects6 = ax.bar(ind+5*width, np.asarray([confusionArrayRBFKernel[5], confusionArrayRBFKernel[5]]), width, color='b')\n",
    "rects7 = ax.bar(ind+6*width, np.asarray([confusionArrayNN[5], confusionArrayNN[5]]), width, color='magenta')\n",
    "\n",
    "#rects5 = ax2.bar(ind+4*width, np.asarray([beta0[4], beta1[4], beta2[4]]), width, color='pink')\n",
    "fontSize = 20\n",
    "#ax.set_title(r'$Sd(\\hat{\\beta})/\\hat{\\beta},\\;$ Noise term: %.2f' %self.noise)\n",
    "ax.set_xticks((ind + width)*1.2 )#/ 2)\n",
    "variableNames = ['Accuracy', 'AUC']\n",
    "ax.set_xticklabels(variableNames)\n",
    "legends = ['Logistic', 'SVM', 'SVM poly', 'SVM poly kernel', 'SVM RBF kernel', 'NN']\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(legends, loc='center left', bbox_to_anchor=(1, 0.5)\\\n",
    ", fontsize = fontSize)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "numerOfVariables = 1\n",
    "ind = np.arange(numerOfVariables)  \n",
    "width = 0.15       # the width of the bars\n",
    "rects2 = ax.bar(ind+1*width, np.asarray([confusionArrayLogreg[3][1,1]]), width, color='green')\n",
    "rects3 = ax.bar(ind+2*width, np.asarray([confusionArraySVMNormal[3][1,1]]), width, color='grey')\n",
    "rects4 = ax.bar(ind+3*width, np.asarray([confusionArraySVMPoly[3][1,1]]), width, color='yellow')\n",
    "rects5 = ax.bar(ind+4*width, np.asarray([confusionArraySvmKernel[3][1,1]]), width, color='r')\n",
    "rects6 = ax.bar(ind+5*width, np.asarray([confusionArrayRBFKernel[3][1,1]]), width, color='b')\n",
    "rects7 = ax.bar(ind+6*width, np.asarray([confusionArrayNN[3][1,1]]), width, color='magenta')\n",
    "\n",
    "#rects5 = ax2.bar(ind+4*width, np.asarray([beta0[4], beta1[4], beta2[4]]), width, color='pink')\n",
    "fontSize = 20\n",
    "ax.set_title('True negative')\n",
    "ax.set_xticks((ind + width)*12 )#/ 2)\n",
    "#variableNames = ['Accuracy', 'AUC']\n",
    "#ax.set_xticklabels(variableNames)\n",
    "legends = ['Logistic', 'SVM', 'SVM poly', 'SVM poly kernel', 'SVM RBF kernel', 'NN']\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(legends, loc='center left', bbox_to_anchor=(1, 0.5)\\\n",
    ", fontsize = fontSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "Yeh, I-C. and Lien, C-h. (2009). The comparisons of data mining techniques for the predictive\n",
    "accuracy of probability of default of credit card clients. <br>\n",
    "_Expert Systems with Applications_ 36 (2009) 2473–2480. <br>\n",
    "https://bradzzz.gitbooks.io/ga-seattle-dsi/content/dsi/dsi_05_classification_databases/2.1-lesson/assets/datasets/DefaultCreditCardClients_yeh_2009.pdf\n",
    "\n",
    "Pyzhov, V. and Pyzhov, S. (2017). Comparison of methods of data mining\n",
    "techniques for the predictive accuracy. _MPRA Paper_ No. 79326. <br>\n",
    "https://mpra.ub.uni-muenchen.de/79326/1/MPRA_paper_79326.pdf\n",
    "\n",
    "Geron, A. (2017). Hands-on machine learning with Sci-Kit learn and Tensorflow. O'Reilly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
